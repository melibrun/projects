{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from Bio.PDB import *\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общие функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfasta(filename):\n",
    "    infile = open(filename, \"r\") #открываем файл\n",
    "    cath = {}\n",
    "    for line in infile:\n",
    "        line = line.strip() #делаем файл в одну строчку\n",
    "        if line.startswith(\">\"): #ищем символ который начинает с \n",
    "            fields1 = line.split(\"|\") #разделяем нашедшуюся линию по проблеам\n",
    "            fields1 = str(fields1)\n",
    "            name1 = fields1[0][1:] #это то как мы определяем имя\n",
    "            cath[fields1] = \"\" #и пустую последовательность строчную\n",
    "        else:\n",
    "            cath[fields1] =  cath[fields1] + line.strip() #1) создали ключ сек 2) добавили туда строчки, которые начинаются не с галочки\n",
    "    #infile.close()\n",
    "    #print(len(cath))\n",
    "    return cath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remooveuseless(inter):\n",
    "    inter1 = {}\n",
    "    for ku, vu in inter.items():\n",
    "        if (len(vu) <= 60):\n",
    "            inter1[ku] = vu\n",
    "    return inter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printer(inter_uniq1):\n",
    "    strings1 = [] \n",
    "    for key,item in inter_uniq1.items():\n",
    "        strings1.append(\">{} \\n{}\".format(key, item))\n",
    "    result1 = \"\\n\".join(strings1)\n",
    "    return result1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение дерева в питоне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Phylo\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "from Bio import AlignIO\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(in_file, out_file):\n",
    "    muscle_exe = r\"C://tmp/muscle.exe\"\n",
    "    # MuscleCommandline( muscle_exe, input=in_file, out=out_file)\n",
    "    # muscle_cline = MuscleCommandline(muscle_exe, align=in_file, out=out_file)\n",
    "    # print(muscle_cline)\n",
    "    process = subprocess.run(muscle_exe + ' -align \"' + in_file+ '\" -output \"'+out_file+'\"', shell=True)\n",
    "    print(process.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_me_tree(filename):\n",
    "    aln = AlignIO.read(filename, 'fasta')\n",
    "    calculator = DistanceCalculator('blosum45')\n",
    "    dm = calculator.get_distance(aln)\n",
    "    constructor = DistanceTreeConstructor()\n",
    "    tree = constructor.nj(dm)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    ch = readfasta(pref+\"in/\"+name)\n",
    "    ch = remooveuseless(ch)\n",
    "    f = printer(ch)\n",
    "    g = open(pref+\"mid/not_aligned_\"+name,\"w\")\n",
    "    g.write(f)\n",
    "    g.close()\n",
    "    align(pref+\"mid/not_aligned_\"+name,pref+\"mid/aligned_\"+name)\n",
    "    ch = make_me_tree(pref+\"mid/aligned_\"+name)\n",
    "    #f = printer(ch)\n",
    "    Phylo.write(ch, pref+\"out/\"+name[:-6]+\".xml\", \"phyloxml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа со вторичной структурой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_df(f):\n",
    "    #filename = filename.replace('\\','/'')\n",
    "    #with open (filename) as f:\n",
    "      aa_sp = []\n",
    "      twostruc_sp = []\n",
    "      fut_df = {}\n",
    "      for line in f:\n",
    "        p = line.replace(\" \",\"\")\n",
    "            \n",
    "        if p[0].isdigit() == True:\n",
    "          line = line.split(\" \")\n",
    "          line = ' '.join(line).split()\n",
    "              \n",
    "          aa_sp.append(line[1])\n",
    "          twostruc_sp.append(line[2])\n",
    "      fut_df[str(aa_sp)] = twostruc_sp\n",
    "      fut_sp2 = {}\n",
    "      for ki, wi in fut_df.items():\n",
    "        ki = str(ki)\n",
    "        wi = str(wi)\n",
    "        fut_sp2[ki] = wi\n",
    "\n",
    "      c = pd.DataFrame(list(fut_sp2.items()),\n",
    "                        columns=['aa', '2st'])\n",
    "      c[\"aa\"] = c[\"aa\"].str.replace('\\W','', regex=True)\n",
    "      c[\"2st\"] = c[\"2st\"].str.replace('\\W','', regex=True)\n",
    "      return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1 = []\n",
    "for element in os.listdir(r\"\\\\wsl.localhost\\Debian\\home\\sa\\bio\\weights\\s4pred\\output_0_40\"):\n",
    "    with open (os.path.join(r\"\\\\wsl.localhost\\Debian\\home\\sa\\bio\\weights\\s4pred\\output_0_40\", element)) as f:\n",
    "        c = do_one_df(f)\n",
    "        sp1.append(c)\n",
    "c = pd.DataFrame(np.concatenate(sp1), columns=[\"aa\", \"2st\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c[c['2st'].str.contains(r'H') == False]\n",
    "c = c[c['2st'].str.contains(r'E') == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = dict(zip(c[\"aa\"], c[\"2st\"]))\n",
    "names = {}\n",
    "for ki, wi in po.items():\n",
    "    for ci, vi in all.items():\n",
    "        if ki == vi:\n",
    "            sp = []\n",
    "            sp.append(wi)\n",
    "            sp.append(ki)\n",
    "            names[ci] = sp\n",
    "new_with_names = pd.DataFrame(names.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(new_with_names[1].to_list(), columns=['2st','aa'])\n",
    "df3.insert(0, \"names\", new_with_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apd3 = readfasta(r\"C:\\Users\\melib\\Downloads\\AMP\\APD3\\APD_sequence_release_09142020.fasta.txt\")\n",
    "v_20_40 = {}\n",
    "for ki, wi in apd3.items():\n",
    "    if len(wi) <=20 or (len(wi) >=35 and len(wi) <=40):\n",
    "        v_20_40[ki] = wi\n",
    "len(v_20_40)\n",
    "printer(v_20_40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аннотация на красивое дерево"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "читаем дерево (по id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_sp = []\n",
    "with open(r\"C:\\Users\\melib\\Downloads\\MFTI\\newick_unrooted\", \"r\") as tree:\n",
    "    for line in tree:\n",
    "        line = line.split(\"A\")\n",
    "        for name in line:\n",
    "            sup = name[-5::]\n",
    "            sup = sup.replace(\"(\", \"\")\n",
    "            sup = sup.replace(\",\", \"\")\n",
    "            sup_sp.append(sup)\n",
    "sup_sp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### распределяем по заряду/гидрофобности"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тут идет парсинг apd3 для получения данных о заряде/гидрофобности/активности/откуда получен амп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_hyt(file,sp):\n",
    "   # sp=[]\n",
    "#    html_doc = open(r\"C:\\Users\\melib\\Downloads\\AMP\\annotate\\hydro\\hydro3.html\", encoding=\"utf8\")\n",
    "    soup = BeautifulSoup(file, 'html.parser')\n",
    "    t = soup.select(\"input\")\n",
    "    t = str(t)\n",
    "    for i in range(len(t)):\n",
    "#    print(t[i:i+7])\n",
    "        if t[i:i+7]=='value=\"':\n",
    "         sp.append(t[i+8:i+12])\n",
    "   \n",
    "\n",
    "    return set(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt={}\n",
    "for file in os.listdir(r'C:\\Users\\melib\\Downloads\\AMP\\annotate\\net'):\n",
    "    if Path(file).suffix == \".html\":\n",
    "         dt[file]=[]\n",
    "         with open(os.path.join(r\"C:\\Users\\melib\\Downloads\\AMP\\annotate\\net\", file), 'r', encoding=\"utf8\") as html_doc:\n",
    "            #for i in rangenet):\n",
    "            \n",
    "               ppp = net_hyt(html_doc,dt[file])\n",
    "               dt[file]=ppp\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(r'C:\\Users\\melib\\Downloads\\AMP\\annotate\\hydro'):\n",
    "    if Path(file).suffix == \".html\":\n",
    "         dt[file]=[]\n",
    "         with open(os.path.join(r\"C:\\Users\\melib\\Downloads\\AMP\\annotate\\hydro\", file), 'r', encoding=\"utf8\") as html_doc:\n",
    "            #for i in rangenet):\n",
    "            \n",
    "               ppp = net_hyt(html_doc,dt[file])\n",
    "               dt[file]=ppp\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = {}\n",
    "for id in sup_sp:\n",
    "    for k, v in dt.items():\n",
    "        if \"net\" in k and id in v:\n",
    "            dt1[id+\"A\"]=[]\n",
    "            netcharge=k[3::].replace(\".html\", \"\")\n",
    "            dt1[id+\"A\"].append(netcharge)\n",
    "    for k, v in dt.items():\n",
    "        if \"hydro\" in k and id in v:\n",
    "            #dt1[id]=[]\n",
    "            hydrocharge=k[5::].replace(\".html\", \"\")\n",
    "            dt1[id+\"A\"].append(hydrocharge)\n",
    "\n",
    "dt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(dt1, orient='index')\n",
    "df.to_csv(\"annot_ex_shape.txt\", sep = \",\", header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### распределяем позвы/беспы + по активности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_anim = readfasta(r\"C:\\Users\\melib\\Downloads\\AMP\\APD3\\APD_sequence_release_09142020.fasta.txt\")\n",
    "invertebrates=[]\n",
    "vertebrates=[]\n",
    "other = []\n",
    "for ki in in_anim.keys():\n",
    "    ki1 = ki.split(\",\")\n",
    "    if \"invertebrates\" in ki:\n",
    "        invertebrates.append(ki1[0])\n",
    "    else:\n",
    "        if \"animals\" in ki:\n",
    "            vertebrates.append(ki1[0])\n",
    "        else:\n",
    "            other.append(ki1[0])\n",
    "print(invertebrates, len(invertebrates), vertebrates, len(vertebrates), other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annot_clade_range(col1,col2,col3):\n",
    "    dt = {}\n",
    "    with open(r\"C:\\Users\\melib\\Downloads\\AMP\\gram_p_m.txt\", \"r\") as gram_m:\n",
    "         for line in gram_m:\n",
    "            line = line.split(\",\")\n",
    "        \n",
    "            for el in line:\n",
    "                el=el[-5:-1]\n",
    "            #print(el)\n",
    "                for ell in sup_sp:\n",
    "                    if el in ell:\n",
    "                        dt[el+\"A\"]=[]\n",
    "                        dt[el+\"A\"].append(\"range\")\n",
    "                        dt[el+\"A\"].append(col1)\n",
    "                    \n",
    "                        dt[el+\"A\"].append(\"gramm negative & gramm positive\")\n",
    "                    #dt[el+\"A\"] =  + \", gramm negative & gramm positive\"\n",
    "\n",
    "\n",
    "    with open(r\"C:\\Users\\melib\\Downloads\\AMP\\gram_m.txt\", \"r\") as gram_m:\n",
    "         for line in gram_m:\n",
    "            line = line.split(\",\")\n",
    "        \n",
    "            for el in line:\n",
    "                el=el[-5:-1]\n",
    "          #  print(el)\n",
    "                for ell in sup_sp:\n",
    "                    if el in ell:\n",
    "                        dt[el+\"A\"]=[]\n",
    "                        dt[el+\"A\"].append(\"range\")\n",
    "                        dt[el+\"A\"].append(col2)\n",
    "                    \n",
    "                        dt[el+\"A\"].append(\"gramm negative\")\n",
    "                    #dt[el+\"A\"] =  + \", gramm negative\"\n",
    "\n",
    "    with open(r\"C:\\Users\\melib\\Downloads\\AMP\\gram_p.txt\", \"r\") as gram_m:\n",
    "         for line in gram_m:\n",
    "            line = line.split(\",\")\n",
    "        \n",
    "            for el in line:\n",
    "                el=el[-5:-1]\n",
    "           # print(el)\n",
    "                for ell in sup_sp:\n",
    "                    if el in ell:\n",
    "                        dt[el+\"A\"]=[]\n",
    "                        dt[el+\"A\"].append(\"range\")\n",
    "                        dt[el+\"A\"].append(col3)\n",
    "                    \n",
    "                        dt[el+\"A\"].append(\"gramm positive\")\n",
    "                   # dt[el+\"A\"] = \"#ffe599\" + \", gramm positive\"\n",
    "            \n",
    "    return dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annot_shape(symb1,s1,col1,pos1,symb2,s2,col2,pos2):\n",
    "    dt = {}\n",
    "    with open(r\"C:\\Users\\melib\\Downloads\\AMP\\APD3\\APD_sequence_release_09142020.fasta.txt\", \"r\") as gram_m:\n",
    "         for line in gram_m:\n",
    "            line = line.split(\">\")\n",
    "        \n",
    "      \n",
    "            for ell in sup_sp:\n",
    "                    for el in line:\n",
    "                     if ell in el and \"def\" in el:\n",
    "                        dt[ell+\"A\"]=[] #id\n",
    "                        dt[ell+\"A\"].append(symb1) #symbol\n",
    "                        dt[ell+\"A\"].append(s1) #size\n",
    "                        dt[ell+\"A\"].append(col1) #color\n",
    "                        dt[ell+\"A\"].append(\"1\") #fill\n",
    "                        dt[ell+\"A\"].append(pos1) #position\n",
    "                   # dt[ell+\"A\"].append(\"gramm negative & gramm positive\")\n",
    "                     if ell in el and \"cathelicidin\" in el:\n",
    "                        dt[ell+\"A\"]=[] #id\n",
    "                        dt[ell+\"A\"].append(symb2) #symbol\n",
    "                        dt[ell+\"A\"].append(s2) #size\n",
    "                        dt[ell+\"A\"].append(col2) #color\n",
    "                        dt[ell+\"A\"].append(\"1\") #fill\n",
    "                        dt[ell+\"A\"].append(pos2) #position\n",
    "    return dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annot_label(col1, col2, col3):\n",
    "   # invertebrates\n",
    "    anim_other={}\n",
    "    for elem in sup_sp:\n",
    "        for el in invertebrates:\n",
    "            if elem in el:\n",
    "                anim_other[elem+\"A\"]=[] #id\n",
    "                anim_other[elem+\"A\"].append(\"label\")\n",
    "                anim_other[elem+\"A\"].append(\"node\")\n",
    "                anim_other[elem+\"A\"].append(\"#000000\")\n",
    "                anim_other[elem+\"A\"].append(\"1\")\n",
    "                anim_other[elem+\"A\"].append(\"normal\")\n",
    "                anim_other[elem+\"A\"].append(col1)\n",
    "        for el1 in vertebrates:\n",
    "            if elem in el1:\n",
    "                anim_other[elem+\"A\"]=[] #id\n",
    "                anim_other[elem+\"A\"].append(\"label\")\n",
    "                anim_other[elem+\"A\"].append(\"node\")\n",
    "                anim_other[elem+\"A\"].append(\"#000000\")\n",
    "                anim_other[elem+\"A\"].append(\"1\")\n",
    "                anim_other[elem+\"A\"].append(\"normal\")\n",
    "                anim_other[elem+\"A\"].append(col2)\n",
    "        for el2 in other:\n",
    "            if elem in el2:\n",
    "                anim_other[elem+\"A\"]=[] #id\n",
    "                anim_other[elem+\"A\"].append(\"label\")\n",
    "                anim_other[elem+\"A\"].append(\"node\")\n",
    "                anim_other[elem+\"A\"].append(\"#000000\")\n",
    "                anim_other[elem+\"A\"].append(\"1\")\n",
    "                anim_other[elem+\"A\"].append(\"normal\")\n",
    "                anim_other[elem+\"A\"].append(col3)\n",
    "    return anim_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = annot_clade_range(\"#b4a7d6\",\"#ffd966\",\"#6fa8dc\")\n",
    "dt1 = annot_shape(\"3\",\"15\", \"#f44336\", \"0.8\", \"1\", \"15\", \"#8fce00\", \"0.8\")\n",
    "anim_other = annot_label(\"#1223456\", \"#adbcca\", \"#89730a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "итоговое дерево строилось на itol"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## парсинг пдб"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "чтобы удостовериться, что имена нигде не перепутаны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(x):\n",
    "    structure = pdb_parser.get_structure(\"PHA-L\",x)\n",
    "    counter = 1\n",
    "    for polypeptide in polypeptide_builder.build_peptides(structure):\n",
    "        seq = polypeptide.get_sequence()\n",
    "    #print(f\"Sequence: {counter}, Length: {len(seq)}\")\n",
    "    #print(seq)\n",
    "        counter += 1\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_name={}\n",
    "for file in os.listdir(r\"C:\\Users\\melib\\Downloads\\AMP\\def+cath\"):\n",
    "\n",
    "   with open(os.path.join(r\"C:\\Users\\melib\\Downloads\\AMP\\def+cath\", file), 'r') as struc:\n",
    "    #print(struc)\n",
    "    name1 = name(struc)\n",
    "   # name1 = name(file)\n",
    "    sp_name[file]=name1\n",
    "sp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cath_def = readfasta(r\"C:\\Users\\melib\\Downloads\\AMP\\APD3\\APD_sequence_release_09142020.fasta.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_na={}\n",
    "for ki, wi in cath_def.items():\n",
    "    for ci, vi in sp_name.items():\n",
    "        if wi in vi:\n",
    "            right_na[ki[-4::]]=ci\n",
    "right_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, v in right_na.items():\n",
    " for filename in os.listdir(r\"C:\\Users\\melib\\Downloads\\AMP\\def+cath\"):\n",
    "\n",
    "    if filename == v:\n",
    "        c = c + \".pdb\"\n",
    "        os.rename(os.path.join(r\"C:\\Users\\melib\\Downloads\\AMP\\def+cath\",filename),os.path.join(r\"C:\\Users\\melib\\Downloads\\AMP\\def+cath\\new\",c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(r\"C:\\Users\\melib\\Downloads\\Telegram Desktop\\final\\final\"):\n",
    "    for i in range(196):\n",
    "        #print(f'def{i}_')\n",
    "        if f\"def{i}_\" in filename and \"ranked_1\" in filename:\n",
    "            os.rename(os.path.join(r\"C:\\Users\\melib\\Downloads\\Telegram Desktop\\final\\final\",filename),os.path.join(r\"C:\\Users\\melib\\Downloads\\AMP\\def+cath\",\"s\"+str(i)+\".pdb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40dbf69e52cc40820e0b1b9eca6a636f0b386a255a6940bc5796a66aff3ef71d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
